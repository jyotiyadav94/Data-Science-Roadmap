# Model Deployments

We are using an asynchronous architecture. Asynchronous tasks are designed to execute concurrently or in the background, allowing the program to continue its operation without waiting for the completion of the task. The key characteristic of asynchronous tasks is that they don't block the execution of the main program. Instead of waiting for a task to finish before moving on to the next one, the program can initiate an asynchronous task and continue with other operations. Queue management provides an elegant solution by allowing asynchronous execution of these resource-intensive tasks.

## Solution Architecture

![Alt text](<Images/Screenshot 2024-01-21 at 15.50.41.png>)

The architecture is built using 3 main building blocks:

- **Flask:** Framework that serves the main application that exposes a minimal interface and the actual API endpoints. Chosen for fast and easy API development. Valid alternatives could be Django, FastAPI.

- **Celery:** Celery is an open-source distributed task queue system that allows you to execute tasks asynchronously. It supports various message brokers, including Redis, so the workers handle the elaboration while the main Flask application returns immediately an "ok" message to the client.

- **RabbitMQ (Redis in the picture):** RabbitMQ is an open-source message broker software that facilitates communication between different systems, applications, or components by implementing a message queue system. It is designed to manage the sending, receiving, and routing of messages between various distributed applications. The message broker collects the task coming from the main application with each API call and proceeds to distribute them to one of the workers, storing the task status (PENDING, SUCCESS, FAILED) and collecting the results once the workers finish their tasks. (*) In this case (both in the picture and in our solution) we are using the same technology to collect requests and to return results, but it can actually be decoupled.

This architecture is useful for exposing asynchronous APIs, which is typically necessary whenever it's required that the backend performs longer tasks (from seconds even to minutes or hours). This is the typical situation for all ML applications. The typical interaction proceeds as follows:

1. A client sends an API request to the main endpoint, uploading a document, and receives a positive response containing the task id.
2. In the background, the broker stores the request (with its id) as "PENDING" and forwards it to the first available worker.
3. At all times the client can query another endpoint, e.g., https://host/elab_status/, to get the status of its task.
4. The worker starts its job, processing the document (the core of the solution is actually performed by the worker).
5. At the end of its long task, the worker returns the result to the broker, that changes the status to "SUCCESS".
6. Once the client receives a "SUCCESS" status from the status endpoint, it can query another endpoint dedicated to retrieving the result, e.g., https://host/elab_result/, obtaining the processed data.

In the current solution, we adopted some atypical settings to fit it to our requirements, as discussed in the dedicated paragraph.

## Project Structure

![Alt text](<Images/Screenshot 2024-01-21 at 15.58.14.png>)

### Docker Compose

![Alt text](<Images/Screenshot 2024-01-21 at 16.07.52.png>)

Docker Compose is a tool that lets you define and run Multi-Containers apps, even establishing a communication layer between these services. It lets you declare your applicationâ€™s services, networks, volumes, and Configurations in a single file called docker-compose.yml.

**Docker-compose.yaml file:**
```yaml
version: "3.7"
services:

  flask_app:
    build: './flask_app'
    ports:
      - "6002:5000"
    depends_on:
      - rabbit
    volumes:
      - Datavolume:/flask_app/files

  rabbit:
    build: './rabbitmq'
    image: "rabbitmq:3-management"
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=mypass
    ports:
      - "15673:15672"
      - "5673:5672"
      - "1884:1883"

  ml_worker:
    build: './ml_worker'
    user: nobody
    depends_on:
      - rabbit
      - flask_app
    volumes:
      - Datavolume:/flask_app/files

volumes:
  Datavolume:
```
