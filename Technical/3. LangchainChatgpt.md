# What is LangChain?

The term "Lang" stands for large language models like GPT-4 from OpenAI, and "chain" stands for connecting these language models with external sources. LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It enables developers to combine LLMs with other external components for various natural language processing (NLP) applications.

## Features of LangChain:
- Data-aware: Connect a language model to other sources of data.
- API for interacting with LLMs.
- Pre-trained LLMs available for use.
- Tools for training and fine-tuning LLMs.
- Agentic: Allow a language model to interact with its environment.

### Applications:
- Chatbots
- Question-answering systems
- Text summarization systems
- Creative writing tools
- Educational tools
- Business intelligence tools

## How LangChain Works:

LangChain is comprised of several modules that facilitate the development of effective NLP applications:

1. **Model Interaction:**
   - Manages inputs and extracts information from language models.

2. **Data Connection and Retrieval:**
   - Transforms and retrieves data accessed by LLMs.

3. **Chains:**
   - Links multiple LLMs or other components to build complex applications.

4. **Agents:**
   - Allows LLMs to decide the best actions by orchestrating commands.

5. **Memory:**
   - Helps LLMs remember the context of interactions.


# Explanation of Provided Code:

```python
import gradio as gr
import os
import re
import pandas as pd
from PyPDF2 import PdfReader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
import json

def process_pdf(open_ai_key,file, query):
    if open_ai_key is not None:
        os.environ['OPENAI_API_KEY'] = open_ai_key
        # Read data from the PDF file and put them into a variable called raw_text
        reader = PdfReader(file.name)
        raw_text = ''
        for i, page in enumerate(reader.pages):
            text = page.extract_text()
            if text:
                raw_text += text
    
        # Split the text into smaller chunks
        text_splitter = CharacterTextSplitter(separator="\n", chunk_size=1000, chunk_overlap=200, length_function=len)
        texts = text_splitter.split_text(raw_text)
    
        # Download embeddings from OpenAI
        embeddings = OpenAIEmbeddings()
    
        # Create FAISS vector store from the text chunks
        docsearch = FAISS.from_texts(texts, embeddings)
    
        # Load the question-answering chain
        chain = load_qa_chain(OpenAI(), chain_type="stuff")
    
        # Perform information retrieval and question answering
        docs = docsearch.similarity_search(query)
        output = chain.run(input_documents=docs, question=query)

        # Split the string by newlines
        values_list = output.split("\n")
        
        # Create an empty dictionary to store the details
        details = {}
        
        # Extract the key-value pairs from the list
        for item in values_list:
            key_value = item.split(": ", 1)
            if len(key_value) == 2:
                key, value = key_value
                details[key.strip()] = value.strip()
        
        # Create a DataFrame from the dictionary
        df = pd.DataFrame(list(details.items()), columns=['Key', 'Value'])
        return df

open_ai_key = gr.Textbox(label="You OpenAI API key", type="password")
file_input = gr.inputs.File(label="Select a PDF file")
query_input = gr.inputs.Textbox(label="Enter the query")
#output = gr.outputs.Textbox(label="Result in JSON")



examples=[[os.environ.get("OPENAI_API_KEY"),"Benetti.pdf",'''Please extract the following details from the PDF:
LC Number:
Date of Issue:
Applicant:
Beneficiary:
Port of Loading:
Port of Discharge:
Latest Date of Shipment:
Description:
Example of a dataframe format for the extracted details:
    Key                 Value
  key_1 :                value_1
  key_2 :                value_2
'''],

[os.environ.get("OPENAI_API_KEY"),"B-L BIESSE PER ALGERI - ALGERIA - CNAN..pdf",'''Please extract the following details from the PDF:
Shipper:
Consignee:
Notify:
Port of Loading:
Port of Discharge:
Description of goods:
Container Quantity:
Container id
Seal Number
Package Qantity
Gross weight
Example of a dataframe format for the extracted details:
    Key                 Value
  key_1 :                value_1
  key_2 :                value_2
''']



]    

title = "Interactive demo: Chat With PDF"
description = "This ChatPDF Chatbot allows you to extract specific information from a PDF document. To get started, please provide your Open API Key for authentication. Next, upload the PDF file from which you want to extract information. Finally, you can write your own query specifying the details you want to extract."

iface = gr.Interface(fn=process_pdf, inputs=[open_ai_key,file_input, query_input], outputs="dataframe",
                    examples=examples,
                     title=title,
                     description=description,)
iface.launch()

```

## OpenAI, LangChain, and FAISS Integration

### OpenAI Overview

OpenAI is a company that specializes in developing Large Language Models (LLMs). These models are trained on extensive datasets of text and code, enabling them to perform tasks such as text generation, language translation, creative content creation, and informative question answering. OpenAI's LLMs are particularly powerful for extracting information from documents, providing natural and informative answers.

### LangChain Framework

LangChain ü¶úÔ∏èüîó is a framework designed for building applications powered by language models. It offers modular abstractions for working with LLMs and leverages their reasoning capabilities to perform various tasks. LangChain simplifies the development of applications that utilize LLMs.

### FAISS - Facebook AI Similarity Search

FAISS, or Facebook AI Similarity Search, is a library that facilitates similarity search algorithms. It efficiently retrieves relevant documents based on semantic similarities. With high-dimensional indexing capabilities and fast search performance, FAISS acts as a compass, guiding towards the most pertinent documents stored as vectors.

FAISS is a library for similarity search, unlocking the power of algorithms to efficiently retrieve relevant documents based on semantic similarities. It utilizes high-dimensional indexing capabilities and fast search performance.

#### Similarity Search Process:

1. **Vector Representation:**
   - Documents are represented as vectors in a high-dimensional space.
   - Vector representation is created using embeddings.

2. **Vector Store:**
   - FAISS creates a vector store, organizing and indexing vectors for efficient similarity searches.

3. **Similarity Metric:**
   - Cosine similarity or Euclidean distance measures similarity between vectors.

4. **Search Process:**
   - Given a query vector, the system searches for documents similar to the query in the vector store.

### Answering Questions from a Document

The process of answering questions from a document involves several key steps:

1. **Splitting the Document into Smaller Chunks:**
   - Utilize document loaders provided by LangChain, such as PyPDFLoader, to load and split documents into smaller chunks.For example, the gpt-3.5-turbo model has max token limit of 4096 tokens shared between the prompt and completion.LangChain has a Character TextSplitter tool that can be used here. It works by splitting text into smaller chunks This is essential as LLMs have a token limit, and breaking the document allows for efficient processing.

    ![Alt text](<Images/Screenshot 2024-01-23 at 13.43.31.png>)

2. **Converting Chunks into Embeddings:**
   - Embeddings are numerical representations capturing the semantic essence of words, phrases, or sentences. LangChain provides an abstraction for interfacing with embedding models, leveraging the embeddings model from OpenAI. FAISS is employed to convert these chunks and embeddings into vectors.

   ![Alt text](<Images/Screenshot 2024-01-23 at 13.44.03.png>)

3. **Performing Similarity Search on Embeddings:**
   - Use advanced algorithms like FAISS to conduct a similarity search on embeddings. This search identifies embeddings that closely resemble the content sought. Similarity search on embeddings helps find relevant information in documents.

   ![Alt text](<Images/Screenshot 2024-01-23 at 13.44.24.png>)

4. **Generating Answers Using an LLM:**
   - LangChain orchestrates the process by passing the question and the most similar chunks from FAISS to the LLM. The LLM then generates a text response relevant to the question. LangChain's RetrievalQA chain facilitates this task.

   ![Alt text](<Images/Screenshot 2024-01-23 at 13.44.41.png>)

### Conclusion

This integration of LangChain, OpenAI, and FAISS provides a seamless process for extracting information from PDF documents based on user queries. The steps involved are outlined, showcasing the capabilities of each component. An example of interacting with a PDF document containing the constitution of the United States is also provided.


